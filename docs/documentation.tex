\documentclass[paper=A4,pagesize=auto,13pt,headinclude=true,footinclude=true,BCOR=0mm,DIV=calc]{scrartcl}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage[scaled]{uarial}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{eurosym}
\usepackage{color}
\usepackage{subfigure}
\usepackage{listings}
\usepackage{float}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{wrapfig}
\usepackage{setspace}
\usepackage[font=footnotesize]{caption}
\usepackage[format=plain,
justification=RaggedRight,
singlelinecheck=false]
{caption}
\usepackage{textcomp}
\geometry{
	left=2.5cm,
	right=2.5cm,
	top=2.5cm,
	bottom=2cm,
}
\makeatletter
\newcommand{\MSonehalfspacing}{%
	\setstretch{1.44}%  default
	\ifcase \@ptsize \relax % 10pt
	\setstretch {1.44}%
	\or % 11pt
	\setstretch {1.44}%
	\or % 12pt
	\setstretch {1.44}%
	\fi
}
\MSonehalfspacing
\setlength{\parindent}{0pt}

\begin{document}
	
	\title{Github Repository Classifier}
	\author{\textbf{Rami Aly$^{1}$, Andre Schurat}$^{2}$\\
		$^{1}$ University of Hamburg\\
		$^{2}$ Technical University of Dortmund}
	\maketitle
	
	\newpage
	
	\section{Abstract}
	
	
	\newpage
	
	\tableofcontents 
	
	\newpage
	\section{Selecting features} 
	
	
	\section{Gathering selected features from Github}
	
	
	
	\section{Removing irrelevant information from selected features}

	
	
	\section{Building the Prediction Model}
	\subsection{Choosing a prediction Model}
	Of course there are many different approaches to the problem. A static algorithm to classify repositories is rather impractical because the parameters of our classify function would be strongly influenced by our interpretation of weights of the features for each class. However we quickly noticed that the complexity is very high, so that a normal algorithm must limit the aspects which can be considered. Above all the problem is non-linear and through the static analysis we would loose the possibility to freely improve or change the classifier. As the software and use-case market of Github rises the possible need of further classes could arise.
	
	Hence to  ensure a classifier who is as dynamic and as extensible as possible we choose to use some form of machine learning.
	The problem which needs to be solved by the Prediction Model is a classification problem: We have a fixed number of values for selected features as input and as an output the class to which the values fit the most. As a result of this fact it was pretty clear to us that a supervised learning method would be optimal.
	
	In the next step we thought about the pro- and contra arguments of non-parametic and parametic learning.
	For example Gaussian-Process-Models could be used in principle, as one does not need to specify a fixed number of parameters and therefore be non-parametic. 
	The main problem with Gaussian-Process-Models is that they scale rather poorly with a complexity of $O(n^{3})$ \cite{DukeUniversity}. Moreover if we keep the huge dimension of repository datasets in mind and as such the possible complexity of the classifier function, our choice will lead us to a parametic neural Network.
	
	
	
%	For this type of classification problem we whereregre
	
	
	\section{Training Set}
	
	\section{Optimizing our Neural Network }

	
	\section{Validation of created Classifier}
	
	\section{Extensions}
	
	
	
	\newpage
	
	\begin{thebibliography}{xxxxxx}
		\bibitem [1] {DukeUniversity} Gaussian Processes 2006, David P. Williams \url{http://people.ee.duke.edu/~lcarin/David1.27.06.pdf}
	\end{thebibliography}
	
	
	\section{Source Code and used external Libraries}
	\paragraph{Source Code}
	Github: \url{https://github.com/Crigges/InformatiCup2017}\\

\end{document}



